{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb36e37b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bcb6a8434a9448b9596183af4a4e903",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/7.16k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "388e14cffbaa4639a3b898f33f9ea552",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading metadata:   0%|          | 0.00/37.4k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8892c54584a04a0eb601338c3b0592f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/15.0k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset amazon_reviews_multi/en to C:/Users/Mir Info/.cache/huggingface/datasets/amazon_reviews_multi/en/1.0.0/724e94f4b0c6c405ce7e476a6c5ef4f87db30799ad49f765094cf9770e0f7609...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3985c36e45ec426ab245a373c70b5070",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28ef51692c784a29bd20af876c7f8674",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/82.0M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e65d1a3bdb845adaee17cf2d854f69f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28d66f6df4bf464e9995ffc403d2c49f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b07f9518cf8e4c51ab474887fb7f4804",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/2.06M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "988b9139b1c2480f9390c677b07c3447",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "558d527eb0c04aa4b2518b49658a8a33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "571477177e144446954dee6680c14152",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/2.05M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41d251ca7bd5498482f9ef30513ec7c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/200000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/5000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/5000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset amazon_reviews_multi downloaded and prepared to C:/Users/Mir Info/.cache/huggingface/datasets/amazon_reviews_multi/en/1.0.0/724e94f4b0c6c405ce7e476a6c5ef4f87db30799ad49f765094cf9770e0f7609. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset amazon_reviews_multi (C:/Users/Mir Info/.cache/huggingface/datasets/amazon_reviews_multi/en/1.0.0/724e94f4b0c6c405ce7e476a6c5ef4f87db30799ad49f765094cf9770e0f7609)\n",
      "Found cached dataset amazon_reviews_multi (C:/Users/Mir Info/.cache/huggingface/datasets/amazon_reviews_multi/en/1.0.0/724e94f4b0c6c405ce7e476a6c5ef4f87db30799ad49f765094cf9770e0f7609)\n"
     ]
    }
   ],
   "source": [
    "#install dataset from HF and store it on pandas dataframe \n",
    "#!pip install datasets \n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "#the dataset is downloaded from hugging face\n",
    "#Note: When experimenting on other datasets, it needs to be arranged in this manner \n",
    "#https://huggingface.co/datasets/amazon_reviews_multi\n",
    "\n",
    "train_ds = load_dataset(\"amazon_reviews_multi\", \"en\", split='train')\n",
    "val_ds = load_dataset(\"amazon_reviews_multi\", \"en\", split='validation')\n",
    "test_ds = load_dataset(\"amazon_reviews_multi\", \"en\", split='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "460c5bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#store as pandas dataframe \n",
    "import pandas as pd\n",
    "df_train = pd.DataFrame(train_ds)\n",
    "df_val = pd.DataFrame(val_ds)\n",
    "df_test = pd.DataFrame(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f32c5a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#filtering the dataset by cutting off reviews and titles that are too small \n",
    "\n",
    "cutoff_title = 5\n",
    "cutoff_body = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d1dbfd56",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train[(df_train['review_title'].apply(lambda x: len(x.split()) >= cutoff_title)) & (df_train['review_body'].apply(lambda x: len(x.split()) >= cutoff_body))]\n",
    "df_val = df_val[(df_val['review_title'].apply(lambda x: len(x.split()) >= cutoff_title)) & (df_val['review_body'].apply(lambda x: len(x.split()) >= cutoff_body))]\n",
    "df_test = df_test[(df_test['review_title'].apply(lambda x: len(x.split()) >= cutoff_title)) & (df_test['review_body'].apply(lambda x: len(x.split()) >= cutoff_body))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9c99cf08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56287 1428 1403\n"
     ]
    }
   ],
   "source": [
    "#limit the size of the dataset for faster training \n",
    "print(len(df_train), len(df_val), len(df_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4d945796",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.sample(20000, random_state=42)\n",
    "df_train = df_train.rename(columns={\"review_body\": \"text\", \"review_title\": \"summary\"})\n",
    "\n",
    "df_val = df_val.sample(1000, random_state=42)\n",
    "df_val = df_val.rename(columns={\"review_body\": \"text\", \"review_title\": \"summary\"})\n",
    "\n",
    "df_test = df_test.sample(1000, random_state=42)\n",
    "df_test = df_test.rename(columns={\"review_body\": \"text\", \"review_title\": \"summary\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "68368254",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arrived broken. Manufacturer defect. Two of the legs of the base were not completely formed, so there was no way to insert the casters. I unpackaged the entire chair and hardware before noticing this. So, I'll spend twice the amount of time boxing up the whole useless thing and send it back with a 1-star review of part of a chair I never got to sit in. I will go so far as to include a picture of what their injection molding and quality assurance process missed though. I will be hesitant to buy again. It makes me wonder if there aren't missing structures and supports that don't impede the assembly process.\n"
     ]
    }
   ],
   "source": [
    "print(df_train['text'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bc1f1af6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'll spend twice the amount of time boxing up the whole useless thing and send it back with a 1-star review ...\""
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[\"summary\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b0693c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the data as CSV file and upload to S3\n",
    "\n",
    "df_train.to_csv('C:/Users/Mir Info/Projects/speech_to_text/train.csv', index=False, columns=['text', 'summary'])\n",
    "df_val.to_csv('C:/Users/Mir Info/Projects/speech_to_text/val.csv', index=False, columns=['text', 'summary'])\n",
    "df_test.to_csv('C:/Users/Mir Info/Projects/speech_to_text/test.csv', index=False, columns=['text', 'summary'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d691c7f",
   "metadata": {},
   "source": [
    "##### Do not run this cell code if you do not have an AWS server for model testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8f6ae2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d5a0f4a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "session = boto3.session.Session(region_name='us-west-2')\n",
    "sm_client = session.client('sagemaker')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "bc311142",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'aws' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "'aws' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "'aws' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "#I do not have a AWS account, for the moment the model dataset and model training will be done locally \n",
    "!aws s3 cp C:/Users/Mir Info/Projects/speech_to_text/train.csv s3://<destination>/train.csv\n",
    "!aws s3 cp C:/Users/Mir Info/Projects/speech_to_text/val.csv s3://<destination>/val.csv\n",
    "!aws s3 cp C:/Users/Mir Info/Projects/speech_to_text/test.csv s3://<destination>/test.csv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c19aa164",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e7b8d9",
   "metadata": {},
   "source": [
    "#### Creating a baseline score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b649c1b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting transformers==4.6.1\n",
      "  Downloading transformers-4.6.1-py3-none-any.whl (2.2 MB)\n",
      "     ---------------------------------------- 2.2/2.2 MB 485.9 kB/s eta 0:00:00\n",
      "Collecting datasets[s3]==1.6.2\n",
      "  Downloading datasets-1.6.2-py3-none-any.whl (221 kB)\n",
      "     ------------------------------------ 221.8/221.8 kB 564.1 kB/s eta 0:00:00\n",
      "Requirement already satisfied: filelock in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers==4.6.1) (3.6.0)\n",
      "Collecting huggingface-hub==0.0.8 (from transformers==4.6.1)\n",
      "  Downloading huggingface_hub-0.0.8-py3-none-any.whl (34 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\mir info\\appdata\\roaming\\python\\python39\\site-packages (from transformers==4.6.1) (1.22.4)\n",
      "Requirement already satisfied: packaging in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers==4.6.1) (21.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers==4.6.1) (2022.7.9)\n",
      "Requirement already satisfied: requests in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers==4.6.1) (2.28.1)\n",
      "Collecting sacremoses (from transformers==4.6.1)\n",
      "  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n",
      "     ------------------------------------ 880.6/880.6 kB 497.4 kB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting tokenizers<0.11,>=0.10.1 (from transformers==4.6.1)\n",
      "  Downloading tokenizers-0.10.3-cp39-cp39-win_amd64.whl (2.0 MB)\n",
      "     ---------------------------------------- 2.0/2.0 MB 489.5 kB/s eta 0:00:00\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers==4.6.1) (4.64.1)\n",
      "Requirement already satisfied: pyarrow>=1.0.0<4.0.0 in c:\\users\\mir info\\appdata\\roaming\\python\\python39\\site-packages (from datasets[s3]==1.6.2) (11.0.0)\n",
      "Requirement already satisfied: dill in c:\\users\\mir info\\appdata\\roaming\\python\\python39\\site-packages (from datasets[s3]==1.6.2) (0.3.6)\n",
      "Requirement already satisfied: pandas in c:\\programdata\\anaconda3\\lib\\site-packages (from datasets[s3]==1.6.2) (1.4.4)\n",
      "Collecting tqdm>=4.27 (from transformers==4.6.1)\n",
      "  Downloading tqdm-4.49.0-py2.py3-none-any.whl (69 kB)\n",
      "     -------------------------------------- 69.8/69.8 kB 476.3 kB/s eta 0:00:00\n",
      "Requirement already satisfied: xxhash in c:\\users\\mir info\\appdata\\roaming\\python\\python39\\site-packages (from datasets[s3]==1.6.2) (3.2.0)\n",
      "Requirement already satisfied: multiprocess in c:\\users\\mir info\\appdata\\roaming\\python\\python39\\site-packages (from datasets[s3]==1.6.2) (0.70.14)\n",
      "Requirement already satisfied: fsspec in c:\\programdata\\anaconda3\\lib\\site-packages (from datasets[s3]==1.6.2) (2022.7.1)\n",
      "Collecting boto3==1.16.43 (from datasets[s3]==1.6.2)\n",
      "  Downloading boto3-1.16.43-py2.py3-none-any.whl (130 kB)\n",
      "     ------------------------------------ 130.2/130.2 kB 641.5 kB/s eta 0:00:00\n",
      "Collecting botocore==1.19.52 (from datasets[s3]==1.6.2)\n",
      "  Downloading botocore-1.19.52-py2.py3-none-any.whl (7.2 MB)\n",
      "     ---------------------------------------- 7.2/7.2 MB 220.0 kB/s eta 0:00:00\n",
      "Collecting s3fs (from datasets[s3]==1.6.2)\n",
      "  Downloading s3fs-2023.4.0-py3-none-any.whl (28 kB)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from boto3==1.16.43->datasets[s3]==1.6.2) (0.10.0)\n",
      "Collecting s3transfer<0.4.0,>=0.3.0 (from boto3==1.16.43->datasets[s3]==1.6.2)\n",
      "  Downloading s3transfer-0.3.7-py2.py3-none-any.whl (73 kB)\n",
      "     -------------------------------------- 73.4/73.4 kB 579.2 kB/s eta 0:00:00\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from botocore==1.19.52->datasets[s3]==1.6.2) (2.8.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in c:\\programdata\\anaconda3\\lib\\site-packages (from botocore==1.19.52->datasets[s3]==1.6.2) (1.26.11)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->transformers==4.6.1) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->transformers==4.6.1) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->transformers==4.6.1) (2022.9.14)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from packaging->transformers==4.6.1) (3.0.9)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\mir info\\appdata\\roaming\\python\\python39\\site-packages (from pandas->datasets[s3]==1.6.2) (2023.2)\n",
      "Collecting aiobotocore~=2.5.0 (from s3fs->datasets[s3]==1.6.2)\n",
      "  Downloading aiobotocore-2.5.0-py3-none-any.whl (72 kB)\n",
      "     -------------------------------------- 72.7/72.7 kB 568.0 kB/s eta 0:00:00\n",
      "Collecting fsspec (from datasets[s3]==1.6.2)\n",
      "  Downloading fsspec-2023.4.0-py3-none-any.whl (153 kB)\n",
      "     ------------------------------------ 154.0/154.0 kB 297.0 kB/s eta 0:00:00\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in c:\\users\\mir info\\appdata\\roaming\\python\\python39\\site-packages (from s3fs->datasets[s3]==1.6.2) (3.8.4)\n",
      "Requirement already satisfied: six in c:\\programdata\\anaconda3\\lib\\site-packages (from sacremoses->transformers==4.6.1) (1.16.0)\n",
      "Requirement already satisfied: click in c:\\programdata\\anaconda3\\lib\\site-packages (from sacremoses->transformers==4.6.1) (8.0.4)\n",
      "Requirement already satisfied: joblib in c:\\programdata\\anaconda3\\lib\\site-packages (from sacremoses->transformers==4.6.1) (1.1.0)\n",
      "INFO: pip is looking at multiple versions of aiobotocore to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting s3fs (from datasets[s3]==1.6.2)\n",
      "  Downloading s3fs-2023.3.0-py3-none-any.whl (27 kB)\n",
      "Collecting aiobotocore~=2.4.2 (from s3fs->datasets[s3]==1.6.2)\n",
      "  Downloading aiobotocore-2.4.2-py3-none-any.whl (66 kB)\n",
      "     -------------------------------------- 66.8/66.8 kB 403.8 kB/s eta 0:00:00\n",
      "Collecting fsspec (from datasets[s3]==1.6.2)\n",
      "  Downloading fsspec-2023.3.0-py3-none-any.whl (145 kB)\n",
      "     ------------------------------------ 145.4/145.4 kB 577.6 kB/s eta 0:00:00\n",
      "Collecting s3fs (from datasets[s3]==1.6.2)\n",
      "  Downloading s3fs-2023.1.0-py3-none-any.whl (27 kB)\n",
      "Collecting fsspec (from datasets[s3]==1.6.2)\n",
      "  Downloading fsspec-2023.1.0-py3-none-any.whl (143 kB)\n",
      "     ------------------------------------ 143.0/143.0 kB 606.4 kB/s eta 0:00:00\n",
      "Collecting s3fs (from datasets[s3]==1.6.2)\n",
      "  Downloading s3fs-2022.11.0-py3-none-any.whl (27 kB)\n",
      "Collecting fsspec (from datasets[s3]==1.6.2)\n",
      "  Downloading fsspec-2022.11.0-py3-none-any.whl (139 kB)\n",
      "     ------------------------------------ 139.5/139.5 kB 590.1 kB/s eta 0:00:00\n",
      "Collecting aiobotocore~=2.4.0 (from s3fs->datasets[s3]==1.6.2)\n",
      "  Downloading aiobotocore-2.4.1-py3-none-any.whl (66 kB)\n",
      "     -------------------------------------- 66.8/66.8 kB 452.3 kB/s eta 0:00:00\n",
      "  Downloading aiobotocore-2.4.0-py3-none-any.whl (65 kB)\n",
      "     -------------------------------------- 65.8/65.8 kB 711.8 kB/s eta 0:00:00\n",
      "Collecting s3fs (from datasets[s3]==1.6.2)\n",
      "  Downloading s3fs-2022.10.0-py3-none-any.whl (27 kB)\n",
      "Collecting fsspec (from datasets[s3]==1.6.2)\n",
      "  Downloading fsspec-2022.10.0-py3-none-any.whl (138 kB)\n",
      "     ------------------------------------ 138.8/138.8 kB 549.3 kB/s eta 0:00:00\n",
      "INFO: pip is looking at multiple versions of aiobotocore to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting s3fs (from datasets[s3]==1.6.2)\n",
      "  Downloading s3fs-2022.8.2-py3-none-any.whl (27 kB)\n",
      "Collecting fsspec (from datasets[s3]==1.6.2)\n",
      "  Downloading fsspec-2022.8.2-py3-none-any.whl (140 kB)\n",
      "     ------------------------------------ 140.8/140.8 kB 490.8 kB/s eta 0:00:00\n",
      "Collecting s3fs (from datasets[s3]==1.6.2)\n",
      "  Downloading s3fs-2022.8.1-py3-none-any.whl (27 kB)\n",
      "Collecting fsspec (from datasets[s3]==1.6.2)\n",
      "  Downloading fsspec-2022.8.1-py3-none-any.whl (140 kB)\n",
      "     ------------------------------------ 140.8/140.8 kB 643.2 kB/s eta 0:00:00\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "Collecting s3fs (from datasets[s3]==1.6.2)\n",
      "  Downloading s3fs-2022.8.0-py3-none-any.whl (27 kB)\n",
      "Collecting fsspec (from datasets[s3]==1.6.2)\n",
      "  Downloading fsspec-2022.8.0-py3-none-any.whl (140 kB)\n",
      "     ------------------------------------ 141.0/141.0 kB 599.8 kB/s eta 0:00:00\n",
      "Collecting s3fs (from datasets[s3]==1.6.2)\n",
      "  Downloading s3fs-2022.7.1-py3-none-any.whl (27 kB)\n",
      "Collecting aiobotocore~=2.3.4 (from s3fs->datasets[s3]==1.6.2)\n",
      "  Downloading aiobotocore-2.3.4-py3-none-any.whl (64 kB)\n",
      "     -------------------------------------- 64.7/64.7 kB 499.2 kB/s eta 0:00:00\n",
      "Collecting s3fs (from datasets[s3]==1.6.2)\n",
      "  Downloading s3fs-2022.7.0-py3-none-any.whl (27 kB)\n",
      "Collecting fsspec (from datasets[s3]==1.6.2)\n",
      "  Downloading fsspec-2022.7.0-py3-none-any.whl (141 kB)\n",
      "     ------------------------------------ 141.2/141.2 kB 598.0 kB/s eta 0:00:00\n",
      "Collecting s3fs (from datasets[s3]==1.6.2)\n",
      "  Downloading s3fs-2022.5.0-py3-none-any.whl (27 kB)\n",
      "Collecting fsspec (from datasets[s3]==1.6.2)\n",
      "  Downloading fsspec-2022.5.0-py3-none-any.whl (140 kB)\n",
      "     ------------------------------------ 140.6/140.6 kB 595.3 kB/s eta 0:00:00\n",
      "Collecting aiobotocore~=2.3.0 (from s3fs->datasets[s3]==1.6.2)\n",
      "  Downloading aiobotocore-2.3.3.tar.gz (65 kB)\n",
      "     -------------------------------------- 65.7/65.7 kB 596.5 kB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "  Downloading aiobotocore-2.3.2.tar.gz (104 kB)\n",
      "     ------------------------------------ 104.8/104.8 kB 433.9 kB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "  Downloading aiobotocore-2.3.1.tar.gz (65 kB)\n",
      "     -------------------------------------- 65.3/65.3 kB 390.6 kB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "  Downloading aiobotocore-2.3.0.tar.gz (65 kB)\n",
      "     -------------------------------------- 65.1/65.1 kB 291.9 kB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting s3fs (from datasets[s3]==1.6.2)\n",
      "  Downloading s3fs-2022.3.0-py3-none-any.whl (26 kB)\n",
      "Collecting aiobotocore~=2.2.0 (from s3fs->datasets[s3]==1.6.2)\n",
      "  Downloading aiobotocore-2.2.0.tar.gz (59 kB)\n",
      "     -------------------------------------- 59.7/59.7 kB 211.4 kB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting fsspec (from datasets[s3]==1.6.2)\n",
      "  Downloading fsspec-2022.3.0-py3-none-any.whl (136 kB)\n",
      "     ------------------------------------ 136.1/136.1 kB 260.0 kB/s eta 0:00:00\n",
      "Collecting s3fs (from datasets[s3]==1.6.2)\n",
      "  Downloading s3fs-2022.2.0-py3-none-any.whl (26 kB)\n",
      "Collecting aiobotocore~=2.1.0 (from s3fs->datasets[s3]==1.6.2)\n",
      "  Downloading aiobotocore-2.1.2.tar.gz (58 kB)\n",
      "     -------------------------------------- 58.7/58.7 kB 283.2 kB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting fsspec (from datasets[s3]==1.6.2)\n",
      "  Downloading fsspec-2022.2.0-py3-none-any.whl (134 kB)\n",
      "     ------------------------------------ 134.9/134.9 kB 163.0 kB/s eta 0:00:00\n",
      "Collecting aiobotocore~=2.1.0 (from s3fs->datasets[s3]==1.6.2)\n",
      "  Downloading aiobotocore-2.1.1.tar.gz (57 kB)\n",
      "     -------------------------------------- 57.5/57.5 kB 252.5 kB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "  Downloading aiobotocore-2.1.0.tar.gz (54 kB)\n",
      "     -------------------------------------- 54.6/54.6 kB 355.0 kB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting s3fs (from datasets[s3]==1.6.2)\n",
      "  Downloading s3fs-2022.1.0-py3-none-any.whl (25 kB)\n",
      "Collecting fsspec (from datasets[s3]==1.6.2)\n",
      "  Downloading fsspec-2022.1.0-py3-none-any.whl (133 kB)\n",
      "     ------------------------------------ 133.2/133.2 kB 523.3 kB/s eta 0:00:00\n",
      "Collecting s3fs (from datasets[s3]==1.6.2)\n",
      "  Downloading s3fs-2021.11.1-py3-none-any.whl (25 kB)\n",
      "Collecting aiobotocore~=2.0.1 (from s3fs->datasets[s3]==1.6.2)\n",
      "  Downloading aiobotocore-2.0.1.tar.gz (54 kB)\n",
      "     -------------------------------------- 54.5/54.5 kB 316.2 kB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting fsspec (from datasets[s3]==1.6.2)\n",
      "  Downloading fsspec-2021.11.1-py3-none-any.whl (132 kB)\n",
      "     ------------------------------------ 133.0/133.0 kB 163.7 kB/s eta 0:00:00\n",
      "Collecting s3fs (from datasets[s3]==1.6.2)\n",
      "  Downloading s3fs-2021.11.0-py3-none-any.whl (25 kB)\n",
      "Collecting aiobotocore~=1.4.1 (from s3fs->datasets[s3]==1.6.2)\n",
      "  Downloading aiobotocore-1.4.2.tar.gz (52 kB)\n",
      "     -------------------------------------- 52.5/52.5 kB 245.8 kB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting fsspec (from datasets[s3]==1.6.2)\n",
      "  Downloading fsspec-2021.11.0-py3-none-any.whl (132 kB)\n",
      "     ------------------------------------ 132.4/132.4 kB 269.7 kB/s eta 0:00:00\n",
      "Collecting aiobotocore~=1.4.1 (from s3fs->datasets[s3]==1.6.2)\n",
      "  Downloading aiobotocore-1.4.1.tar.gz (52 kB)\n",
      "     -------------------------------------- 52.3/52.3 kB 298.4 kB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting s3fs (from datasets[s3]==1.6.2)\n",
      "  Downloading s3fs-2021.10.1-py3-none-any.whl (26 kB)\n",
      "Collecting fsspec (from datasets[s3]==1.6.2)\n",
      "  Downloading fsspec-2021.10.1-py3-none-any.whl (125 kB)\n",
      "     ------------------------------------ 125.6/125.6 kB 409.2 kB/s eta 0:00:00\n",
      "Collecting s3fs (from datasets[s3]==1.6.2)\n",
      "  Downloading s3fs-2021.10.0-py3-none-any.whl (26 kB)\n",
      "Collecting fsspec (from datasets[s3]==1.6.2)\n",
      "  Downloading fsspec-2021.10.0-py3-none-any.whl (125 kB)\n",
      "     ------------------------------------ 125.0/125.0 kB 490.5 kB/s eta 0:00:00\n",
      "Collecting s3fs (from datasets[s3]==1.6.2)\n",
      "  Downloading s3fs-2021.9.0-py3-none-any.whl (26 kB)\n",
      "Collecting fsspec (from datasets[s3]==1.6.2)\n",
      "  Downloading fsspec-2021.9.0-py3-none-any.whl (123 kB)\n",
      "     ------------------------------------ 123.6/123.6 kB 603.1 kB/s eta 0:00:00\n",
      "Collecting s3fs (from datasets[s3]==1.6.2)\n",
      "  Downloading s3fs-2021.8.1-py3-none-any.whl (26 kB)\n",
      "Collecting fsspec (from datasets[s3]==1.6.2)\n",
      "  Downloading fsspec-2021.8.1-py3-none-any.whl (119 kB)\n",
      "     ------------------------------------ 119.3/119.3 kB 537.3 kB/s eta 0:00:00\n",
      "Collecting aiobotocore~=1.4.0 (from s3fs->datasets[s3]==1.6.2)\n",
      "  Downloading aiobotocore-1.4.0.tar.gz (51 kB)\n",
      "     -------------------------------------- 51.6/51.6 kB 530.5 kB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting s3fs (from datasets[s3]==1.6.2)\n",
      "  Downloading s3fs-2021.8.0-py3-none-any.whl (26 kB)\n",
      "Collecting fsspec (from datasets[s3]==1.6.2)\n",
      "  Downloading fsspec-2021.7.0-py3-none-any.whl (118 kB)\n",
      "     ------------------------------------ 118.1/118.1 kB 531.2 kB/s eta 0:00:00\n",
      "Collecting s3fs (from datasets[s3]==1.6.2)\n",
      "  Downloading s3fs-2021.7.0-py3-none-any.whl (25 kB)\n",
      "Collecting aiobotocore>=1.0.1 (from s3fs->datasets[s3]==1.6.2)\n",
      "  Downloading aiobotocore-2.0.0.tar.gz (52 kB)\n",
      "     -------------------------------------- 53.0/53.0 kB 182.6 kB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "  Downloading aiobotocore-1.3.3.tar.gz (50 kB)\n",
      "     -------------------------------------- 50.6/50.6 kB 258.7 kB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "  Downloading aiobotocore-1.3.2.tar.gz (49 kB)\n",
      "     -------------------------------------- 49.1/49.1 kB 177.6 kB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "  Downloading aiobotocore-1.3.1.tar.gz (48 kB)\n",
      "     -------------------------------------- 48.8/48.8 kB 308.8 kB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "  Downloading aiobotocore-1.3.0.tar.gz (48 kB)\n",
      "     -------------------------------------- 48.2/48.2 kB 486.3 kB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "  Downloading aiobotocore-1.2.2.tar.gz (48 kB)\n",
      "     -------------------------------------- 48.1/48.1 kB 161.8 kB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: wrapt>=1.10.10 in c:\\programdata\\anaconda3\\lib\\site-packages (from aiobotocore>=1.0.1->s3fs->datasets[s3]==1.6.2) (1.14.1)\n",
      "Collecting aioitertools>=0.5.1 (from aiobotocore>=1.0.1->s3fs->datasets[s3]==1.6.2)\n",
      "  Downloading aioitertools-0.11.0-py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from click->sacremoses->transformers==4.6.1) (0.4.5)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs->datasets[s3]==1.6.2) (21.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\mir info\\appdata\\roaming\\python\\python39\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs->datasets[s3]==1.6.2) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\mir info\\appdata\\roaming\\python\\python39\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs->datasets[s3]==1.6.2) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\mir info\\appdata\\roaming\\python\\python39\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs->datasets[s3]==1.6.2) (1.8.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\mir info\\appdata\\roaming\\python\\python39\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs->datasets[s3]==1.6.2) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\mir info\\appdata\\roaming\\python\\python39\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs->datasets[s3]==1.6.2) (1.3.1)\n",
      "Requirement already satisfied: typing_extensions>=4.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from aioitertools>=0.5.1->aiobotocore>=1.0.1->s3fs->datasets[s3]==1.6.2) (4.3.0)\n",
      "Building wheels for collected packages: aiobotocore, sacremoses\n",
      "  Building wheel for aiobotocore (setup.py): started\n",
      "  Building wheel for aiobotocore (setup.py): finished with status 'done'\n",
      "  Created wheel for aiobotocore: filename=aiobotocore-1.2.2-py3-none-any.whl size=45735 sha256=0b3c7dec389fa74738d55e1e614205e2dbb52959c7ab444884d3da0bcc9a88d5\n",
      "  Stored in directory: c:\\users\\mir info\\appdata\\local\\pip\\cache\\wheels\\5c\\8a\\d9\\8f981e444c8c2d2a0e1f9407fb8caa4d89530381be49a7042a\n",
      "  Building wheel for sacremoses (setup.py): started\n",
      "  Building wheel for sacremoses (setup.py): finished with status 'done'\n",
      "  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895241 sha256=1912a449fdf24cb3db8b4f8b94c1e32472bb7aa34a4f6d888d8c3df00e985532\n",
      "  Stored in directory: c:\\users\\mir info\\appdata\\local\\pip\\cache\\wheels\\12\\1c\\3d\\46cf06718d63a32ff798a89594b61e7f345ab6b36d909ce033\n",
      "Successfully built aiobotocore sacremoses\n",
      "Installing collected packages: tokenizers, tqdm, fsspec, aioitertools, sacremoses, huggingface-hub, botocore, transformers, s3transfer, datasets, aiobotocore, s3fs, boto3\n",
      "  Attempting uninstall: tokenizers\n",
      "    Found existing installation: tokenizers 0.13.3\n",
      "    Uninstalling tokenizers-0.13.3:\n",
      "      Successfully uninstalled tokenizers-0.13.3\n",
      "  Attempting uninstall: huggingface-hub\n",
      "    Found existing installation: huggingface-hub 0.13.4\n",
      "    Uninstalling huggingface-hub-0.13.4:\n",
      "      Successfully uninstalled huggingface-hub-0.13.4\n",
      "  Attempting uninstall: botocore\n",
      "    Found existing installation: botocore 1.29.114\n",
      "    Uninstalling botocore-1.29.114:\n",
      "      Successfully uninstalled botocore-1.29.114\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.27.4\n",
      "    Uninstalling transformers-4.27.4:\n",
      "      Successfully uninstalled transformers-4.27.4\n",
      "  Attempting uninstall: datasets\n",
      "    Found existing installation: datasets 2.11.0\n",
      "    Uninstalling datasets-2.11.0:\n",
      "      Successfully uninstalled datasets-2.11.0\n",
      "  Attempting uninstall: boto3\n",
      "    Found existing installation: boto3 1.26.114\n",
      "    Uninstalling boto3-1.26.114:\n",
      "      Successfully uninstalled boto3-1.26.114\n",
      "Successfully installed aiobotocore-1.2.2 aioitertools-0.11.0 boto3-1.16.43 botocore-1.19.52 datasets-1.6.2 fsspec-2021.7.0 huggingface-hub-0.0.8 s3fs-2021.7.0 s3transfer-0.3.7 sacremoses-0.0.53 tokenizers-0.10.3 tqdm-4.49.0 transformers-4.6.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script tqdm.exe is installed in 'C:\\Users\\Mir Info\\AppData\\Roaming\\Python\\Python39\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script sacremoses.exe is installed in 'C:\\Users\\Mir Info\\AppData\\Roaming\\Python\\Python39\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script huggingface-cli.exe is installed in 'C:\\Users\\Mir Info\\AppData\\Roaming\\Python\\Python39\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script transformers-cli.exe is installed in 'C:\\Users\\Mir Info\\AppData\\Roaming\\Python\\Python39\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script datasets-cli.exe is installed in 'C:\\Users\\Mir Info\\AppData\\Roaming\\Python\\Python39\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "anaconda-project 0.11.1 requires ruamel-yaml, which is not installed.\n",
      "evaluate 0.4.0 requires datasets>=2.0.0, but you have datasets 1.6.2 which is incompatible.\n",
      "evaluate 0.4.0 requires huggingface-hub>=0.7.0, but you have huggingface-hub 0.0.8 which is incompatible.\n",
      "evaluate 0.4.0 requires tqdm>=4.62.1, but you have tqdm 4.49.0 which is incompatible.\n",
      "sagemaker 2.146.1 requires boto3<2.0,>=1.26.28, but you have boto3 1.16.43 which is incompatible.\n",
      "anaconda-client 1.11.0 requires tqdm>=4.56.0, but you have tqdm 4.49.0 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "!pip install \"transformers==4.6.1\" \"datasets[s3]==1.6.2\" --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "fd12606c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mir Info\\AppData\\Local\\Temp\\ipykernel_9644\\2721381364.py:2: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate\n",
      "  metric = load_metric(\"rouge\")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b69127a25c6d4bdb8979933ba9720143",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/2.17k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_metric\n",
    "metric = load_metric(\"rouge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "03f57b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The function is taken from the notebook \n",
    "#https://github.com/huggingface/transformers/blob/v4.6.1/examples/pytorch/summarization/run_summarization.py\n",
    "\n",
    "def calc_rouge_scores(candidates, references):\n",
    "    result = metric.compute(predictions=candidates, references=references, use_stemmer=True)\n",
    "    result = {key: round(value.mid.fmeasure * 100, 1) for key, value in result.items()}\n",
    "    return result "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "bcb80925",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_summaries = list(df_test['summary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "848f0d14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 1 senctences: Scores {'rouge1': 27.1, 'rouge2': 17.5, 'rougeL': 25.7, 'rougeLsum': 25.7}\n",
      "First 2 senctences: Scores {'rouge1': 26.7, 'rouge2': 17.2, 'rougeL': 24.6, 'rougeLsum': 24.6}\n",
      "First 3 senctences: Scores {'rouge1': 24.6, 'rouge2': 15.9, 'rougeL': 22.7, 'rougeLsum': 22.6}\n"
     ]
    }
   ],
   "source": [
    "#comparing the reference texts with the first sentence 3 summaries \n",
    "\n",
    "import re\n",
    "for i in range (3):\n",
    "    candidate_summaries = list(df_test['text'].apply(lambda x: ' '.join(re.split(r'(?<=[.:;])\\s', x)[:i+1])))\n",
    "    print(f\"First {i+1} senctences: Scores {calc_rouge_scores(candidate_summaries, ref_summaries)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7e8fd9d",
   "metadata": {},
   "source": [
    "rouge 1 is a better score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b355a41",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
